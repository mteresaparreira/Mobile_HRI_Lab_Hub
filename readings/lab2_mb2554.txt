This week's reading was important to establish groundings for what a robot is. If we go according to the initial definition of the concept (from the book, "the word “robot” resulted from combining the Czech words rabota, meaning “obligatory work” and robotnik, meaning “serf.” - a machine that does obligatory work), it seems like many things could be a robot. Toasters, washing machines, any appliance would be considered a robot. Yet, this is not the idea that is more generally accepted today, it seems.

This makes me wonder if the concept of a robot evolved as technology evolved. As we were able to achieve more and more complex machines, with added sensors and automated behavior, our idea of "robots" evolved to be in line with the latest technological advances, keeping robots as this "mysterious device" with seemingly impressive capabilities (poor toasters...)

Another question that comes up somewhat in HRI - and which we may even end up discussing in class - is that of the *need* for robots in certain settings. Sometimes, researchers come up with study settings in which the need for a robot may seem forced. For example, I recently reviewed a paper for HRI2023 in which a robot performed automated posture detection to identify erratic behavior in a psychiatric patient. However, the need for an embodied agent, rather than a camera and a speaker, was not made clear. It was a great paper and a novel technical contribution, but the presence of the robot felt forced. My concerns were echoed by other reviewers (I'm not sure if the paper got accepted), and I personally learned to think twice before conceptualizing research questions in HRI - I should always ensure that a robot *adds something* to the setting, rather than have it as a (unrealistic) default presence in an everyday setting.

